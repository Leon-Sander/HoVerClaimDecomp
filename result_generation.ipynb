{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_retrieval import is_successful_retrieval\n",
    "from utils import load_obj\n",
    "\n",
    "# tfidf_retrieval_output_dev_100.json\n",
    "# tfidf_retrieval_output_dev_1000.json\n",
    "# mistral_retrieval_output_dev_100.json\n",
    "# mistral_retrieval_output_dev_1000.json\n",
    "\n",
    "def calculate_success_percentage_supported(data, retrieval_key=\"retrieved\"):\n",
    "    supported_data = [item for item in data if item['label'] == \"SUPPORTED\"]\n",
    "    success_percentages, average_total_percentage = calculate_success_percentage(supported_data, retrieval_key)\n",
    "    return success_percentages, average_total_percentage\n",
    "\n",
    "def calculate_success_percentage_not_supported(data, retrieval_key=\"retrieved\"):\n",
    "    not_supported_data = [item for item in data if item['label'] == \"NOT_SUPPORTED\"]\n",
    "    success_percentages, average_total_percentage = calculate_success_percentage(not_supported_data, retrieval_key)\n",
    "    return success_percentages, average_total_percentage\n",
    "\n",
    "\n",
    "def calculate_success_percentage(data, retrieval_key=\"retrieved\"):\n",
    "    hop_counts = {2: {'total': 0, 'successful': 0},\n",
    "                    3: {'total': 0, 'successful': 0},\n",
    "                    4: {'total': 0, 'successful': 0}}\n",
    "\n",
    "    for obj in data:\n",
    "        num_hops = obj['num_hops']\n",
    "        hop_counts[num_hops][\"total\"] += 1\n",
    "        if is_successful_retrieval(obj, retrieval_key):\n",
    "            hop_counts[num_hops]['successful'] += 1\n",
    "\n",
    "    success_percentages = {}\n",
    "    for num_hops, counts in hop_counts.items():\n",
    "        if counts['total'] > 0:\n",
    "            success_percentage = (counts['successful'] / counts['total']) * 100\n",
    "            success_percentages[num_hops] = success_percentage\n",
    "    #print(hop_counts)\n",
    "    #print(success_percentages)\n",
    "    average_total_percentage = (success_percentages[2] + success_percentages[3] + success_percentages[4]) / 3\n",
    "    return success_percentages, average_total_percentage\n",
    "\n",
    "def calculate_success_percentage_qa(data, retrieval_key, support_type):\n",
    "    hop_counts = {2: {'total': 0, 'successful': 0},\n",
    "                    3: {'total': 0, 'successful': 0},\n",
    "                    4: {'total': 0, 'successful': 0}}\n",
    "\n",
    "\n",
    "    for hop_count in data:\n",
    "        int_hop_count = int(hop_count)\n",
    "        for key in data[hop_count]:\n",
    "            for item in data[hop_count][key]:\n",
    "                #if obj[\"label\"] == \"SUPPORTED\":\n",
    "                if support_type == \"SUPPORTED\":\n",
    "                    if item[\"label\"] == \"SUPPORTED\":\n",
    "                        hop_counts[int_hop_count][\"total\"] += 1\n",
    "                        if is_successful_retrieval(item, retrieval_key=retrieval_key):\n",
    "                            hop_counts[int_hop_count]['successful'] += 1\n",
    "                elif support_type == \"NOT_SUPPORTED\":\n",
    "                        if item[\"label\"] == \"NOT_SUPPORTED\":\n",
    "                            hop_counts[int_hop_count][\"total\"] += 1\n",
    "                            if is_successful_retrieval(item, retrieval_key=retrieval_key):\n",
    "                                hop_counts[int_hop_count]['successful'] += 1\n",
    "                else:\n",
    "                    hop_counts[int_hop_count][\"total\"] += 1\n",
    "                    if is_successful_retrieval(item, retrieval_key=retrieval_key):\n",
    "                        hop_counts[int_hop_count]['successful'] += 1\n",
    "    #print(hop_counts)\n",
    "    success_percentages = {}\n",
    "    for num_hops, counts in hop_counts.items():\n",
    "        if counts['total'] > 0:\n",
    "            success_percentage = (counts['successful'] / counts['total']) * 100\n",
    "            success_percentages[num_hops] = success_percentage\n",
    "\n",
    "\n",
    "    average_total_percentage = (success_percentages[2] + success_percentages[3] + success_percentages[4]) / 3\n",
    "    # Example variables\n",
    "    hops_2 = round(success_percentages[2],2)\n",
    "    hops_3 = round(success_percentages[3],2)\n",
    "    hops_4 = round(success_percentages[4],2)\n",
    "    avg_total = round(average_total_percentage,2)\n",
    "    return success_percentages, average_total_percentage#hops_2, hops_3, hops_4, avg_total\n",
    "\n",
    "\n",
    "def generate_latex_entry_simple(success_percentages, average_total_percentage, method, dataset, retrieved):\n",
    "    hops_2 = round(success_percentages[2],2)\n",
    "    hops_3 = round(success_percentages[3],2)\n",
    "    hops_4 = round(success_percentages[4],2)\n",
    "    avg_total = round(average_total_percentage,2)\n",
    "\n",
    "    #latex_line = f\"{method} & {dataset} & {retrieved} & {hops_2}\\% & {hops_3}\\% & {hops_4}\\% & {avg_total}\\% \\\\\\\\ \\\\hline\\n\"    \n",
    "    latex_line = f\"{method} & {hops_2}\\% & {hops_3}\\% & {hops_4}\\% & {avg_total}\\% \\\\\\\\ \\\\hline\\n\"   \n",
    "    print(latex_line)\n",
    "\n",
    "def generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, method):\n",
    "    hops_2_supp = round(success_percentages_supp[2],2)\n",
    "    hops_3_supp = round(success_percentages_supp[3],2)\n",
    "    hops_4_supp = round(success_percentages_supp[4],2)\n",
    "    avg_total_supp = round(average_total_percentage_supp,2)\n",
    "\n",
    "    hops_2_not_supp = round(success_percentages_not_supp[2],2)\n",
    "    hops_3_not_supp = round(success_percentages_not_supp[3],2)\n",
    "    hops_4_not_supp = round(success_percentages_not_supp[4],2)\n",
    "    avg_total_not_supp = round(average_total_percentage_not_supp,2)\n",
    "\n",
    "    #latex_line = f\"{method} & {dataset} & {retrieved} & {hops_2}\\% & {hops_3}\\% & {hops_4}\\% & {avg_total}\\% \\\\\\\\ \\\\hline\\n\"    \n",
    "    #latex_line = f\"{method} & {hops_2}\\% & {hops_3}\\% & {hops_4}\\% & {avg_total}\\% \\\\\\\\ \\\\hline\\n\"\n",
    "    # TF-IDF & 83.64\\% & 58.13\\% & 29.17\\% & 56.98\\% & 84.84\\% & 58.78\\% & 34.25\\% & 59.29\\% \\\\ \n",
    "    latex_line = f\"{method} & {hops_2_supp}\\% & {hops_3_supp}\\% & {hops_4_supp}\\% & {avg_total_supp}\\%& {hops_2_not_supp}\\% & {hops_3_not_supp}\\% & {hops_4_not_supp}\\% & {avg_total_not_supp}\\% \\\\\\\\\"\n",
    "    print(latex_line)\n",
    "\n",
    "\n",
    "# initial Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF & 69.67\\% & 35.43\\% & 14.09\\% & 39.73\\%& 70.91\\% & 34.14\\% & 12.5\\% & 39.18\\% \\\\\n",
      "Mistral & 74.47\\% & 39.46\\% & 16.44\\% & 43.46\\%& 66.12\\% & 34.95\\% & 17.05\\% & 39.37\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/tfidf_retrieval_output_dev_100.json\"\n",
    "success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_supported(load_obj(data_path))\n",
    "success_percentages_not_supp, average_total_percentage_not_supp = calculate_success_percentage_not_supported(load_obj(data_path))\n",
    "generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, \"TF-IDF\")\n",
    "\n",
    "data_path = \"data/mistral_retrieval_output_dev_100.json\"\n",
    "success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_supported(load_obj(data_path))\n",
    "success_percentages_not_supp, average_total_percentage_not_supp = calculate_success_percentage_not_supported(load_obj(data_path))\n",
    "generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, \"Mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral & 71.21\\% & 37.6\\% & 15.46\\% & 41.42\\%& 63.31\\% & 32.76\\% & 15.15\\% & 37.07\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/mistral_retrieval_output_dev_100_multi_hop_prompt.json\"\n",
    "success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_supported(load_obj(data_path))\n",
    "success_percentages_not_supp, average_total_percentage_not_supp = calculate_success_percentage_not_supported(load_obj(data_path))\n",
    "generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, \"Mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF & 84.84\\% & 58.78\\% & 34.25\\% & 59.29\\%& 83.64\\% & 58.13\\% & 29.17\\% & 56.98\\% \\\\\n",
      "Mistral & 92.71\\% & 69.21\\% & 45.6\\% & 69.17\\%& 87.77\\% & 63.67\\% & 44.7\\% & 65.38\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/tfidf_retrieval_output_dev_1000.json\"\n",
    "success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_supported(load_obj(data_path))\n",
    "success_percentages_not_supp, average_total_percentage_not_supp = calculate_success_percentage_not_supported(load_obj(data_path))\n",
    "generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, \"TF-IDF\")\n",
    "\n",
    "\n",
    "data_path = \"data/mistral_retrieval_output_dev_1000.json\"\n",
    "success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_supported(load_obj(data_path))\n",
    "success_percentages_not_supp, average_total_percentage_not_supp = calculate_success_percentage_not_supported(load_obj(data_path))\n",
    "generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, \"Mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_obj(\"data/decomp_baseline_FULL_DATASET.json\")\n",
    "#data = load_obj('/home/sander/code/thesis/hover/leon/data/decomp_TFIDF_baseline.json')\n",
    "data = load_obj(\"data/decomp_baseline_FULL_DATASET_MISTRAL_AND_TIFIDF.json\")\n",
    "from utils import save_obj\n",
    "run_count = 0\n",
    "## BASELINE\n",
    "for hop_count in data:\n",
    "    for key in data[hop_count]:\n",
    "        for item in data[hop_count][key]:\n",
    "\n",
    "            decomp_retrieval_100 = []\n",
    "            for index in range(100):\n",
    "                for retrieval in item[f\"decomposed_claims_retrieval_{run_count}\"]:\n",
    "                    #\n",
    "                    if len(decomp_retrieval_100) >= 100:\n",
    "                        break\n",
    "                    if index < len(retrieval):\n",
    "                        decomp_retrieval_100.append(retrieval[index])\n",
    "            item[f\"decomposed_claims_retrieval_100_mistral_no_filter\"] = decomp_retrieval_100\n",
    "save_obj(data, \"data/decomp_baseline_FULL_DATASET_MISTRAL_AND_TIFIDF.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_obj\n",
    "for hop_count in data:\n",
    "    for key in data[hop_count]:\n",
    "        for item in data[hop_count][key]:\n",
    "\n",
    "\n",
    "            for run_count in range(4):\n",
    "                if run_count <= int(hop_count) - 1:\n",
    "\n",
    "\n",
    "                    decomp_retrieval_100 = []\n",
    "                    for index in range(100):\n",
    "                        for retrieval in item[f\"decomposed_claims_retrieval_{run_count}\"]:\n",
    "                            #\n",
    "                            if len(decomp_retrieval_100) >= 100:\n",
    "                                break\n",
    "                            if index < len(retrieval):\n",
    "                                decomp_retrieval_100.append(retrieval[index])\n",
    "                    item[f\"decomposed_claims_retrieval_100_combined_{run_count}\"] = decomp_retrieval_100\n",
    "save_obj(data, \"data/iterative_decomp_FULL_DATASET_retrieval_combined.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Qualitative Analysis Data</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 & 80.0\\% & 50.0\\% & 10.0\\% & 46.67\\%& 70.0\\% & 50.0\\% & 10.0\\% & 43.33\\% \\\\\n",
      "10 & 70.0\\% & 50.0\\% & 10.0\\% & 43.33\\%& 60.0\\% & 50.0\\% & 0.0\\% & 36.67\\% \\\\\n",
      "20 & 70.0\\% & 40.0\\% & 10.0\\% & 40.0\\%& 50.0\\% & 50.0\\% & 0.0\\% & 33.33\\% \\\\\n",
      "60 & 70.0\\% & 60.0\\% & 10.0\\% & 46.67\\%& 80.0\\% & 40.0\\% & 10.0\\% & 43.33\\% \\\\\n",
      "80 & 80.0\\% & 40.0\\% & 10.0\\% & 43.33\\%& 70.0\\% & 40.0\\% & 20.0\\% & 43.33\\% \\\\\n",
      "125 & 70.0\\% & 30.0\\% & 0.0\\% & 33.33\\%& 90.0\\% & 40.0\\% & 10.0\\% & 46.67\\% \\\\\n",
      "300 & 60.0\\% & 20.0\\% & 10.0\\% & 30.0\\%& 70.0\\% & 50.0\\% & 0.0\\% & 40.0\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "for threshhold in [5, 10, 20, 60, 80, 125, 300]:\n",
    "    data_path = f\"data/iterative_cross_test_{threshhold}_no_filter.json\"\n",
    "    success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_qa(load_obj(data_path), retrieval_key=\"retrieved_1\", support_type=\"SUPPORTED\")\n",
    "    success_percentages_not_supp, average_total_percentage_not_supp = calculate_success_percentage_qa(load_obj(data_path), retrieval_key=\"retrieved_1\", support_type=\"NOT_SUPPORTED\")\n",
    "    generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, threshhold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 & 75.0\\% & 50.0\\% & 10.0\\% & 45.0\\% \\\\\n",
      "10 & 65.0\\% & 50.0\\% & 5.0\\% & 40.0\\% \\\\\n",
      "20 & 60.0\\% & 45.0\\% & 5.0\\% & 36.67\\% \\\\\n",
      "60 & 75.0\\% & 50.0\\% & 10.0\\% & 45.0\\% \\\\\n",
      "80 & 75.0\\% & 40.0\\% & 15.0\\% & 43.33\\% \\\\\n",
      "125 & 80.0\\% & 35.0\\% & 5.0\\% & 40.0\\% \\\\\n",
      "300 & 65.0\\% & 35.0\\% & 5.0\\% & 35.0\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_entry_multicolumn_all(success_percentages, average_total_percentage, method):\n",
    "    hops_2_supp = round(success_percentages[2],2)\n",
    "    hops_3_supp = round(success_percentages[3],2)\n",
    "    hops_4_supp = round(success_percentages[4],2)\n",
    "    avg_total_supp = round(average_total_percentage,2)\n",
    "\n",
    "    #latex_line = f\"{method} & {dataset} & {retrieved} & {hops_2}\\% & {hops_3}\\% & {hops_4}\\% & {avg_total}\\% \\\\\\\\ \\\\hline\\n\"    \n",
    "    #latex_line = f\"{method} & {hops_2}\\% & {hops_3}\\% & {hops_4}\\% & {avg_total}\\% \\\\\\\\ \\\\hline\\n\"\n",
    "    # TF-IDF & 83.64\\% & 58.13\\% & 29.17\\% & 56.98\\% & 84.84\\% & 58.78\\% & 34.25\\% & 59.29\\% \\\\ \n",
    "    latex_line = f\"{method} & {hops_2_supp}\\% & {hops_3_supp}\\% & {hops_4_supp}\\% & {avg_total_supp}\\% \\\\\\\\\"\n",
    "    print(latex_line)\n",
    "\n",
    "for threshhold in [5, 10, 20, 60, 80, 125, 300]:\n",
    "    data_path = f\"data/iterative_cross_test_{threshhold}_no_filter.json\"\n",
    "    success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_qa(load_obj(data_path), retrieval_key=\"retrieved_1\", support_type=\"ALL\")\n",
    "    generate_latex_entry_multicolumn_all(success_percentages_supp, average_total_percentage_supp, threshhold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomp Mistral & 80.42\\% & 43.7\\% & 24.46\\% & 49.53\\%& 74.55\\% & 39.22\\% & 21.4\\% & 45.05\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "#data_path= \"data/decomp_baseline_TFIDF_FULL_DATASET_100.json\"\n",
    "data_path = \"data/decomp_baseline_FULL_DATASET_MISTRAL_AND_TIFIDF.json\"\n",
    "success_percentages_supp, average_total_percentage_supp = calculate_success_percentage_qa(load_obj(data_path), retrieval_key=\"decomposed_claims_retrieval_100_mistral_no_filter\", support_type=\"SUPPORTED\")\n",
    "success_percentages_not_supp, average_total_percentage_not_supp = calculate_success_percentage_qa(load_obj(data_path), retrieval_key=\"decomposed_claims_retrieval_100_mistral_no_filter\", support_type=\"NOT_SUPPORTED\")\n",
    "generate_latex_entry_multicolumn(success_percentages_supp, average_total_percentage_supp, success_percentages_not_supp, average_total_percentage_not_supp, \"Decomp Mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{\\textit{Hop 2, SUPPORTED}} \\\\\n",
      "Decomp & 80.4\\% & 77.9\\% & - & - & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 2, NOT_SUPPORTED}} \\\\\n",
      "Decomp & 74.5\\% & 70.1\\% & - & - & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 3, SUPPORTED}} \\\\\n",
      "Decomp & 43.5\\% & 48.7\\% & 45.8\\% & - & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 3, NOT_SUPPORTED}} \\\\\n",
      "Decomp & 39.2\\% & 41.6\\% & 39.3\\% & - & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 4, SUPPORTED}} \\\\\n",
      "Decomp & 24.5\\% & 25.8\\% & 23.5\\% & 25.0\\% & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 4, NOT_SUPPORTED}} \\\\\n",
      "Decomp & 21.2\\% & 24.1\\% & 21.8\\% & 20.5\\% & - \\\\\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_rows_for_method_qa(data, max_iter, method, retrieval_key):\n",
    "    # Print rows for each hop count for the specific method\n",
    "    for hop_count in data:\n",
    "        for key in data[hop_count]:\n",
    "        #hop_count = int(hop_count)\n",
    "        # Supported\n",
    "            row_entries_supported = []\n",
    "            print(f\"\\\\multicolumn{{6}}{{l}}{{\\\\textit{{Hop {hop_count}, {key}}}}} \\\\\\\\\")\n",
    "            for i in range(max_iter + 1):\n",
    "                if i <= int(hop_count):\n",
    "                    success = 0\n",
    "                    for item_index, item in enumerate(data[hop_count][key]):\n",
    "                        try:\n",
    "                            success += is_successful_retrieval(item, f\"{retrieval_key}_{i}\")\n",
    "                        except:\n",
    "                            print(f\"error for item: {hop_count}, {key}, {i}, {item_index}\")\n",
    "\n",
    "\n",
    "                    total = sum(1 for item in data[hop_count][key])\n",
    "                    success_rate = success / total * 100 if total > 0 else 0\n",
    "                    row_entries_supported.append(f\"{success_rate:.1f}\\%\")\n",
    "                else:\n",
    "                    row_entries_supported.append(\"-\")\n",
    "            print(method + \" & \" + \" & \".join(row_entries_supported) + \" \\\\\\\\\")\n",
    "\n",
    "#data = load_obj(\"data/iterative_FULL_DATASET_with_questions_60_no_filter.json\")\n",
    "data = load_obj(\"data/iterative_decomp_FULL_DATASET_retrieval_combined.json\")\n",
    "generate_latex_rows_for_method_qa(data, 4, \"Decomp\", \"decomposed_claims_retrieval_100_combined\")\n",
    "\n",
    "## nochmal überprüfen obs hier auch mit rechten Dingen zugeht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['uid', 'supporting_facts', 'label', 'num_hops', 'hpqa_id', 'previous_iteration_sentences', 'claim_0', 'retrieved_0', 'sub_questions_0', 'sub_question_retrieval_0', 'top_sentences_0', 'claim_1', 'retrieved_1', 'sub_questions_1', 'sub_question_retrieval_1', 'top_sentences_1', 'claim_2', 'retrieved_2', 'tfidf_retrieved_0', 'tfidf_retrieved_1', 'tfidf_retrieved_2', 'decomposed_claims_0', 'decomposed_claims_retrieval_0', 'decomposed_claims_1', 'decomposed_claims_retrieval_1', 'decomposed_claims_retrieval_100_combined_0', 'decomposed_claims_retrieval_100_combined_1'])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(data[\"2\"][\"SUPPORTED\"][0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/qualitative_analysis_claims_10_base.json\n",
    "# Alle folgenden experimente basieren auf data/qualitative_analysis_claims_10_base.json\n",
    "\n",
    "# data/iterative_qualitative_analysis_question_answering_60.json\n",
    "# data/iterative_test_base_60_no_filter.json\n",
    "# data/iterative_test_base_60.json\n",
    "# data/iterative_test2.json\n",
    "# data/iterative_test_with_questions.json -> double cross\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_obj\n",
    "qa_data = load_obj(\"data/qualitative_analysis_claims_10_base.json\")\n",
    "setting_data = load_obj(\"data/iterative_test_with_questions.json\")\n",
    "for hop_count in qa_data:\n",
    "    for key in qa_data[hop_count]:\n",
    "        for index, item in enumerate(qa_data[hop_count][key]):\n",
    "            if item[\"claim\"] != setting_data[hop_count][key][index][\"claim\"]:\n",
    "                print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Not Supported analysis</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate for hop 2 iteration 0 SUPPORTED is 70.0%\n",
      "Success rate for hop 2 iteration 0 NOT_SUPPORTED is 70.0%\n",
      "Success rate for hop 2 iteration 1 SUPPORTED is 70.0%\n",
      "Success rate for hop 2 iteration 1 NOT_SUPPORTED is 70.0%\n",
      "Success rate for hop 2 iteration 2 SUPPORTED is 60.0%\n",
      "Success rate for hop 2 iteration 2 NOT_SUPPORTED is 60.0%\n",
      "Success rate for hop 3 iteration 0 SUPPORTED is 40.0%\n",
      "Success rate for hop 3 iteration 0 NOT_SUPPORTED is 40.0%\n",
      "Success rate for hop 3 iteration 1 SUPPORTED is 40.0%\n",
      "Success rate for hop 3 iteration 1 NOT_SUPPORTED is 30.0%\n",
      "Success rate for hop 3 iteration 2 SUPPORTED is 50.0%\n",
      "Success rate for hop 3 iteration 2 NOT_SUPPORTED is 30.0%\n",
      "Success rate for hop 3 iteration 3 SUPPORTED is 60.0%\n",
      "Success rate for hop 3 iteration 3 NOT_SUPPORTED is 30.0%\n",
      "Success rate for hop 4 iteration 0 SUPPORTED is 40.0%\n",
      "Success rate for hop 4 iteration 0 NOT_SUPPORTED is 40.0%\n",
      "Success rate for hop 4 iteration 1 SUPPORTED is 60.0%\n",
      "Success rate for hop 4 iteration 1 NOT_SUPPORTED is 40.0%\n",
      "Success rate for hop 4 iteration 2 SUPPORTED is 60.0%\n",
      "Success rate for hop 4 iteration 2 NOT_SUPPORTED is 30.0%\n",
      "Success rate for hop 4 iteration 3 SUPPORTED is 30.0%\n",
      "Success rate for hop 4 iteration 3 NOT_SUPPORTED is 30.0%\n",
      "Success rate for hop 4 iteration 4 SUPPORTED is 30.0%\n",
      "Success rate for hop 4 iteration 4 NOT_SUPPORTED is 30.0%\n"
     ]
    }
   ],
   "source": [
    "from evaluate_retrieval import is_successful_retrieval\n",
    "from utils import load_obj\n",
    "\n",
    "data = load_obj(\"data/iterative_qualitative_analysis_not_supported_question_answering_80.json\")\n",
    "\n",
    "\n",
    "\n",
    "def calculate_iteration_success(data, hop_count):\n",
    "    \n",
    "    \n",
    "    for i in range(int(hop_count)+1):\n",
    "        success = 0\n",
    "        success_not_supported = 0\n",
    "        total = 0\n",
    "        for item in data:\n",
    "            total += 1\n",
    "            if is_successful_retrieval(item, f\"retrieved_{i}\"):\n",
    "                success += 1\n",
    "            if is_successful_retrieval(item[\"not_supported_counterpart\"], f\"retrieved_{i}\"):\n",
    "                success_not_supported += 1\n",
    "            \n",
    "        print(f\"Success rate for hop {hop_count} iteration {i} SUPPORTED is {success/total * 100}%\")\n",
    "        print(f\"Success rate for hop {hop_count} iteration {i} NOT_SUPPORTED is {success_not_supported/total * 100}%\")\n",
    "\n",
    "for hop_count in data:\n",
    "    calculate_iteration_success(data[hop_count], hop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(data, max_hop_count, max_iter):\n",
    "    for hop_count in range(1, max_hop_count + 1):\n",
    "        hop_count = int(hop_count)\n",
    "        # Print supported and not supported sections for each hop count\n",
    "        print(f\"\\\\multicolumn{{6}}{{l}}{{\\\\textit{{Hop {hop_count}, Supported}}}} \\\\\\\\\")\n",
    "        for config in ['Decomposed', 'Base like Decomposed', 'Base 60 like Decomposed', 'Base 60 no filter like Decomposed', 'Questions Double Cross like Decomposed', 'Questions 60 like Decomposed', 'Questions 60 no filter like Decomposed']:\n",
    "            row_entries = []\n",
    "            for i in range(max_iter + 1):\n",
    "                if i <= hop_count:\n",
    "                    success = sum(is_successful_retrieval(item, f\"retrieved_{i}\") for item in data if item['config'] == config and item['supported'])\n",
    "                    total = sum(1 for item in data if item['config'] == config and item['supported'])\n",
    "                    success_rate = success / total * 100 if total > 0 else 0\n",
    "                    row_entries.append(f\"{success_rate:.1f}%\")\n",
    "                else:\n",
    "                    row_entries.append(\"-\")\n",
    "            print(config + \" & \" + \" & \".join(row_entries) + \" \\\\\\\\\")\n",
    "        \n",
    "        print(f\"\\\\multicolumn{{6}}{{l}}{{\\\\textit{{Hop {hop_count}, Not Supported}}}} \\\\\\\\\")\n",
    "        for config in ['Decomposed', 'Base like Decomposed', 'Base 60 like Decomposed', 'Base 60 no filter like Decomposed', 'Questions Double Cross like Decomposed', 'Questions 60 like Decomposed', 'Questions 60 no filter like Decomposed']:\n",
    "            row_entries = []\n",
    "            for i in range(max_iter + 1):\n",
    "                if i <= hop_count:\n",
    "                    success = sum(is_successful_retrieval(item[\"not_supported_counterpart\"], f\"retrieved_{i}\") for item in data if item['config'] == config and not item['supported'])\n",
    "                    total = sum(1 for item in data if item['config'] == config and not item['supported'])\n",
    "                    success_rate = success / total * 100 if total > 0 else 0\n",
    "                    row_entries.append(f\"{success_rate:.1f}%\")\n",
    "                else:\n",
    "                    row_entries.append(\"-\")\n",
    "            print(config + \" & \" + \" & \".join(row_entries) + \" \\\\\\\\\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_row_for_method(data, max_iter, method, retrieval_key):\n",
    "    # Print rows for each hop count for the specific method\n",
    "    for hop_count in data:\n",
    "        #hop_count = int(hop_count)\n",
    "        # Supported\n",
    "        row_entries_supported = []\n",
    "        print(f\"\\\\multicolumn{{6}}{{l}}{{\\\\textit{{Hop {hop_count}, Supported}}}} \\\\\\\\\")\n",
    "        for i in range(max_iter + 1):\n",
    "            if i <= int(hop_count):\n",
    "                success = sum(is_successful_retrieval(item, f\"{retrieval_key}_{i}\") for item in data[hop_count])\n",
    "                total = sum(1 for item in data[hop_count])\n",
    "                success_rate = success / total * 100 if total > 0 else 0\n",
    "                row_entries_supported.append(f\"{success_rate:.1f}\\%\")\n",
    "            else:\n",
    "                row_entries_supported.append(\"-\")\n",
    "        print(method + \" & \" + \" & \".join(row_entries_supported) + \" \\\\\\\\\")\n",
    "\n",
    "        # Not Supported\n",
    "        row_entries_not_supported = []\n",
    "        print(f\"\\\\multicolumn{{6}}{{l}}{{\\\\textit{{Hop {hop_count}, Not Supported}}}} \\\\\\\\\")\n",
    "        for i in range(max_iter + 1):\n",
    "            if i <= int(hop_count):\n",
    "                success = sum(is_successful_retrieval(item[\"not_supported_counterpart\"], f\"{retrieval_key}_{i}\") for item in data[hop_count])\n",
    "                total = sum(1 for item in data[hop_count])\n",
    "                success_rate = success / total * 100 if total > 0 else 0\n",
    "                row_entries_not_supported.append(f\"{success_rate:.1f}\\%\")\n",
    "            else:\n",
    "                row_entries_not_supported.append(\"-\")\n",
    "        print(method + \" & \" + \" & \".join(row_entries_not_supported) + \" \\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_obj\n",
    "qa_data = load_obj(\"data/qualitative_analysis_claims_10_base.json\")\n",
    "setting_data = load_obj(\"data/iterative_test_with_questions.json\")\n",
    "for hop_count in qa_data:\n",
    "    for index, item in enumerate(qa_data[hop_count]):\n",
    "        if item[\"claim\"] != setting_data[hop_count][index][\"claim\"]:\n",
    "            print(\"ERROR\")\n",
    "\n",
    "# not supported style data\n",
    "# rohdaten: data/qualitative_analysis_not_supported.json\n",
    "\n",
    "# iterative_qualitative_analysis_not_supported_no_filter_80.json\n",
    "# iterative_qualitative_analysis_not_supported_question_answering_80.json\n",
    "# iterative_qualitative_analysis_not_supported_no_filter_80.json -> normales sub question retrieval\n",
    "\n",
    "# iterative_not_supported_subquestions_filter_60.json\n",
    "# iterative_not_supported_base_no_filter_60_100_docs_retrieved.json -> läuft screen 2 DONE\n",
    "# data/iterative_not_supported_subquestions_no_filter_60.json -> DONE\n",
    "# data/iterative_not_supported_subquestions_no_filter_change_prompt_60.json -> DONE\n",
    "# data/iterative_not_supported_question_answering_60.json -> läuft\n",
    "# data/iterative_not_supported_base_no_filter_60_based_on_subquestions.json \n",
    "\n",
    "# \"data/iterative_qualitative_analysis_question_answering_60.json\" screen 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn{6}{l}{\\textit{Hop 2, Supported}} \\\\\n",
      "Subquestions Entity Correction & 70.0\\% & 80.0\\% & 80.0\\% & - & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 2, Not Supported}} \\\\\n",
      "Subquestions Entity Correction & 70.0\\% & 60.0\\% & 70.0\\% & - & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 3, Supported}} \\\\\n",
      "Subquestions Entity Correction & 40.0\\% & 40.0\\% & 40.0\\% & 40.0\\% & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 3, Not Supported}} \\\\\n",
      "Subquestions Entity Correction & 40.0\\% & 30.0\\% & 30.0\\% & 30.0\\% & - \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 4, Supported}} \\\\\n",
      "Subquestions Entity Correction & 40.0\\% & 30.0\\% & 20.0\\% & 20.0\\% & 20.0\\% \\\\\n",
      "\\multicolumn{6}{l}{\\textit{Hop 4, Not Supported}} \\\\\n",
      "Subquestions Entity Correction & 40.0\\% & 30.0\\% & 20.0\\% & 20.0\\% & 20.0\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "from utils import load_obj\n",
    "data= load_obj(\"data/iterative_not_supported_subquestions_no_filter_change_prompt_60.json\")\n",
    "generate_latex_row_for_method(data=data, max_iter=4, method=\"Subquestions Entity Correction\", retrieval_key=\"retrieved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
